---
title: "OSTEP - 가상화: 완전한 가상 메모리 시스템"
lang: "ko"
layout: post
date: 2022-05-30 00:01:13 +0900
categories: [os]
tags: [os]
---

이번 챕터에선 **VAX/VMS** 운영체제와 **Linux** 운영체제가 실제로 어떠한 방식으로 가상 메모리 시스템을 구현하였는지 살펴본다. (다만 꽤 전문적인 내용이여서 조금 어렵게 느껴진다...)  
이번 챕터와 관련은 없지만 문득 궁금했던 내용... 만약 프로그램 사이즈가 주소 공간보다 크다면?  
[https://stackoverflow.com/questions/15965718/what-happens-if-the-size-of-a-program-is-larger-than-virtual-memory](https://stackoverflow.com/questions/15965718/what-happens-if-the-size-of-a-program-is-larger-than-virtual-memory)  
아무튼... 이제 시작해보자.

# VAX/VMS 가상 메모리

VAX/VMS(또는 단순하게 VMS) 운영체제의 아키텍트는 "현대적인" 가상 메모리 관리자를 최초로 구현한 사례로 손꼽히며, 이에 사용된 다양한 기법과 접근법은 현재에도 꾸준히 사용중이라고 한다. VMS는 컴퓨터의 구조적 결함(하드웨어의 결함)을 소프트웨어로 보안한 훌륭한 사례이다.

## 메모리 관리 하드웨어

VAX-11은 프로세스마다 512바이트 페이지 단위로 나누어진 32비트 가상 주소 공간을 제공한다. 가상 주소는 23비트 VPN과 9비트 오프셋으로 구성되어 있다. VPN의 상위 2비트는 페이지가 속한 세그멘트를 나타내기 위해 사용되었으며, 따라서 해당 시스템은 페이징과 세그멘테이션의 하이브리드 구조를 갖고 있다고 말할 수 있다.

주소 공간의 *하위 절반*은 "프로세스 공간(P)"으로, 각 프로세스마다 다르게 할당된다. 해당 공간에는 사용자 프로그램과 힙 그리고 스택이 존재한다. 주소 공간의 *상위 절반*은 그 중 반만 사용되며, 이 공간을 "시스템 공간(S)"로 부른다. 해당 공간에는 운영체제의 보호된 코드와 데이터가 존재하며, 이로 인해 여러 프로세스가 운영체제를 공유할 수 있다.

512바이트 페이지는 아주 작은 크기이므로, 페이지 테이블의 크기가 엄청나게 커질 수 있고, 이는 메모리에 압박을 가할 수 있다. 이를 위해 VAX-11은 "프로세스 공간"을 두 개의 세그멘트로 나누어(P0, P1), 프로세스마다 각 영역을 위한 페이지 테이블을 가지게 함으로써, 페이지 테이블 공간이 스택과 힙 사이의 사용되지 않는 주소 영역을 할당하지 않도록 한다. 그리고 운영체제는 나누어진 페이지 테이블을 커널의 가상 메모리에 배치하여(즉 세그멘트 S에 공간을 할당하여), 페이지 테이블의 페이지들을 물리 메모리에서 디스크로 스왑할 수 있도록 하였다.

## 실제 주소 공간

```
0    +-----------------+ -+
     | page 0: invalid |  |
     +-----------------+  |
     |      code       |  |
     +-----------------+  +--> User (P0) 
     |      heap       |  |
     +-----------------+  |
     |                 |  |
2^30 +=================+ -+
     |                 |  |
     +-----------------+  +--> User (P1)
     |     stack       |  |
2^31 +=================+ -+
     |    trap table   |  |
     +-----------------+  |
     |   kernel data   |  |
     +-----------------+  |
     |   kernel code   |  +--> System (S)
     +-----------------+  |
     |   kernel heap   |  |
     +-----------------+  |
     |                 |  |
     +=================+ -+
     |      unused     |
2^32 +-----------------+

## VMX/VAX 주소 공간 단순화
```
<br />

위 그림을 보면, 페이지 0이 무효 처리 되어있어 접근이 불가능하다. 해당 페이지는 **널-포인터(null-pointer)** 접근을 검출하는 역할을 하며, 효과적인 디버깅을 지원한다. 또한 커널의 요소들이 사용자 주소 공간의 일부로 들어가있는데, 이로 인해 사용자 코드에서 문제가 발생하면(가령 문맥 교환), 운영체제는 주소 공간을 참조하기만 하면 되기에 처리하기 쉬워진다(커널이 자체 주소 공간을 가진다면 사용자 프로그램과 커널 간의 데이터 이동은 매우 복잡해진다). 동시에 운영체제의 자료를 보호하기 위해, 페이지 테이블의 protection bit에 보호 수준을 저장함으로써 페이지 별로 보호 수준을 다르게 설정한다. 즉 특정 페이지에 접근하기 위해선 특별한 권한이 요구된다.

## 페이지 교체

VAX의 페이지 테이블 항목(PTE)은 다음과 같은 비트를 가지고 있다:

1. 유효(valid) 비트
2. 보호 필드(protection field, 4비트)
3. 변경(modify, dirty) 비트
4. 운영체제가 사용하기 위해 예약한 비트(5비트)
5. 물리 프레임 번호(PFN)

<br />
여기에 **참조 비트(reference bit)**가 없는 것을 확인할 수 있다. VAX는 **세그멘트된 FIFO** 교체 정책을 수행함으로써 페이지 교체와 **메모리 호그(memory hog)**(메모리를 너무 많이 사용하는 프로그램)에 대처한다. 작동 원리는 간단하다. 먼저 각 프로세스는 **상주 집합 크기(resident set size, RSS)**(메모리에 유지할 수 있는 최대 페이지 개수)를 지정 받는다. 그리고 각 페이지들이 FIFO 리스트에 보관되며, 만약 페이지 개수가 RSS보다 커지면, *제일 먼저 들어온* 페이지가 쫓겨나는 방식이다.

FIFO의 성능을 개선하기 위해 시스템은 두 개의 **second-chance list**(*전역 클린-페이지 프리 리스트(global clean-page free list)*와 *더티-페이지 리스트(dirty-page list)*)를 도입하였다. 제거되는 페이지의 상태에 따라(수정되었는가? -> 더티, 수정되지 않았는가? -> 클린) 해당 페이지는 그에 맞는 리스트에 들어간다. 그리고 빈 페이지가 요구될 경우, 전역 클린 리스트에서 첫 번쨰 페이지를 꺼내어 디스크 접근을 최대한 피한다. 전역 second-chance list의 크기가 클 수록 세그멘트된 FIFO 알고리즘은 LRU와 유사하게 작동한다.

또한 VMS의 작은 페이지 크기를 극복하기 위해, 스왑의 I/O 효율을 개선하기 위한 최적화 기법으로 **클러스터링(clustering)**을 도입하였다. 클러스터링 기법을 사용하여 VMS는 전역 더티 리스트에 있는 페이지들을 묶어 한 번에 디스크로 보낸다.

## 그 외의 기법들

VMS는 이제는 표준화가 된 두 가지 기법을 더 가지고 있다: **요청시 0으로 채우기(demand zeroing)**와 **쓰기-시-복사(copy-on-write, COW)**.

일반적으로 힙에 페이지를 추가하는 요청이 들어오면, 운영체제는 물리 메모리에서 페이지를 찾아 0으로 채운 후, 주소 공간에 그 페이지를 매핑하는데(즉 페이지 테이블에 항목을 추가함), 만약 프로세스가 해당 페이지를 사용하지 않게 된다면, 많은 비용이 소모되어 버린다. **demand zeroing**은 반대로 해당 페이지를 먼저 페이지 테이블에 추가하고, 접근 불가능으로 설정한다. 만약 프로세스가 해당 페이지를 읽게 된다면, 운영체제로 트랩이 발생하여, 운영체제가 해당 페이지는 demand zeroing 페이지임을 알게 되고(일반적으로 '운영체제가 사용하기 위해 예약한 비트'에 정보가 표기되어 있다), 이후 페이지를 0으로 채우고 주소 공간에 해당 페이지를 매핑한다. demand zeroing에서는 먄약 프로세스가 해당 페이지를 접근하지 않는다면, 페이지를 주소 공간에 매핑하고 0으로 채우는 과정을 모두 생략할 수 있게 된다.

**copy-on-write**는, 운영체제가 주소 공간에서 다른 공간으로 페이지를 복사할 필요가 있을 떄, 복사를 하지 않고 해당 페이지를 대상 주소 공간으로 매핑한다(즉 하나의 물리 페이지를 두 개의 페이지 테이블이 가리키도록 한다). 만약 양쪽 주소 공간이 페이지를 읽기만 한다면, 운영체제는 데이터 이동 없이 빠른 복사를 구현하게 되는 셈이다(불필요한 복사를 피할 수 있게 된다). 만약 한 공간이 페이지 쓰기를 시도한다면, 트랩이 발생하고 운영체제는 해당 페이지가 COW 페이지임을 파악한 후, 새로운 페이지를 할당하여 해당 주소 공간에 매핑한다.

demand-zeroing, copy-on-write는 모두 *게으르게* 일을 처리함으로써, 불필요한 과정을 최소화하여 성능을 개선한다는 공통점이 있다고 말할 수 있을 것 같다.

# Linux 가상 메모리 시스템

가장 많은 수를 차지하고 중요한 배포 버전인 Intel x86용 Linux에 초점을 맞춘다.

## Linux 주소 공간

```sh

0x00000000 +-----------------+ -+
           | page 0: invalid |  |
           +-----------------+  |
           |       code      |  |
           +-----------------+  |
           |       heap      |  |
           +-----------------+  +-> User
           |                 |  |
           |                 |  |
           +-----------------+  |
           |      stack      |  |
0xC0000000 +-----------------+  |
           |                 |  |
           +=================+ -+
           | kernel (logical)|  |
           +-----------------+  |
           | kernel (virtual)|  +-> Kernel
           +-----------------+  |
           |                 |  |
           +-----------------+ -+

## Lunux 주소 공간 단순화
```
<br />

다른 현대적인 운영체제와, 그리고 VAX/VMS와 마찬가지로, Linux 가상 주소 공간은 사용자 영역과 커널 영역으로 구성된다(다만 이 챕터가 쓰여진 이후, 최근 보안 이슈에 의해 구조가 변경되었다고 한다!). 커널 영역은 모든 프로세스에서 동일하며, 사용자 모드에서 실행되는 프로그램은 커널 가상 페이지에 접근할 수 없다.

32비트 가상 주소 공간을 가진 Linux의 주소 공간에서 사용자 영역과 커널 영역을 구분하는 지점은 주소 `0xC0000000` 또는 주소 공간의 3/4 지점이다. Linux의 흥미로운 점은, 커널 가상 주소의 유형이 두 개라는 점이다. 

**커널 논리 주소(kernel logical address)**는 일반적인 커널의 가상 주소 공간이다. 페이지 테이블, 커널 스택 등과 같이, 대부분의 커널 데이터 구조가 이 공간에 존재한다. 흥미롭게도 커널 논리 주소는 물리 메모리의 첫 부분에 직접 매핑된다. 따라서 커널 논리 주소 `0xC0000000`은 물리 주소 `0x00000000`으로 변환된다. 이로 인해 커널 논리 주소와 물리 주소 사이의 변환이 간단해지며, 커널 주소 공간에 할당된 메모리는 연속적인 작업에 적합함을 의미한다(가령, **직접 메모리 접근 방식(direct memory access, DMA)**을 사용한 메모리 사이의 입출력 전송).

**커널 가상 주소(kernel virtual address)**에 할당되는 메모리는 보통 연속적이지 않다. 따라서 각 커널 가상 페이지는 연속하지 않은 물리페이지에 매핑되므로 DMA에는 적합하지 않지만, 이런 형태의 메모리는 결과적으로 더 쉽게 할당될 수 있기에, 연속된 물리 메모리 청크를 찾는 것이 어려운 *대용량 버퍼 할당*에 사용된다. 32bit Linux에 **커널 가상 주소**가 존재하는 또 다른 이유는 커널이 대략 1GB 이상의 메모리를 더 사용할 수 있도록 하기 위함이다.

## 페이지 테이블 구조

x86은 하드웨어가 관리하는, 다중 레벨 페이지 테이블 구조를 제공하며, 프로세스 당 하나의 페이지 테이블이 있다. 운영체제는 프로세스 생성, 삭제, 및 문맥 교환에 관여하며, 각 경우에 주소를 변환할 때 하드웨어가 MMU에 맞는 페이지 테이블을 사용하게 한다. 이후 기술 발전에 의해 64bit로의 변환이 요구된 주소 공간은 일반적으로 4 레벨 페이지 테이블을 사용한다.

## 크기가 큰 페이지 지원

Intel x86은 표준 4KB 페이지에서 1GB 페이지까지 하드웨어로 지원할 수 있다. 거대한 페이지를 사용하면 많은 이점을 얻을 수 있다. 가장 주된 이점은 TLB가 효과적으로 작동하고 그에 따라 성능의 향상을 가져오는 것이다.

프로세스가 많은 양의 메모리를 적극적으로 사용하면 TLB가 변환 결과로 빨리 채워지게 된다. 즉 거대한 페이지를 사용하면 TLB의 더 적은 슬롯을 사용하더라도 *TLB 미스* 없이 매우 큰 메모리 공간에 접근할 수 있다. 또한 TLB 미스가 발생했을 때 더 빠르게 처리될 수도 있다.

하지만 이에 대한 대가도 존재하는데, 크기는 크지만 잘 사용되지 않는 페이지, 즉 **내부 단편화(internal fragmentation)** 문제를 피할 수 없게 된다. 크기가 크지만 거의 사용되지 않는 페이지들이 메모리를 가득 채워버리게 될 수 있다.

## 페이지 캐시

Linux **페이지 캐시(page cache)**는 세 가지 주요 소스로부터 온 페이지를 메모리에 유지할 수 있도록 통합된다: **메모리 맵 파일(memory-mapped files)**, 파일 데이터와 장치의 메타 데이터, 그리고 힙과 프로세스를 구성하는 스택 페이지(**anonymous memory**). 이러한 개체들은 **페이지 캐시 해시 테이블(page cache hash table)**에 보관되므로 데이터가 필요할 때 빠른 검색이 가능하다.

페이지 캐시는 항목의 클린과 더티 여부를 추적하여, 더티 데이터(즉 수정된(modified) 데이터)는 백그라운드 쓰레드에 주기적으로 기록되어, 이후 영구 저장 장치에 다시 기록되게 한다.

리눅스는 **2Q** 교체 알고리즘을 사용하여 어떠한 페이지를 꺼낼지를 결정한다. 2Q 알고리즘은 두 개의 리스트를 유지하여 메모리를 두 부분으로 나눈다. 처음으로 접근되는 페이지는 **비활동 리스트(inactive list)**라 불리는 하나의 큐로 들어간다. 이후 해당 페이지가 다시 접근되면, 이 페이지는 **활동 리스트(active list)**라는 다른 큐로 이동한다. 페이지 교체가 요구되는 경우, 비활동 리스트에 담긴 페이지를 교체 후보로 삼는다. 또한 주기적으로 활동 리스트의 맨 아래 페이지를 비활동 리스트로 이동시킨다. 리스트를 관리하는 알고리즘은 **클록(clock)** 교체 알고리즘과 같은 LRU 근사 알고리즘을 사용한다. 2Q 알고리즘은 일반적으로 LRU와 매우 유사하게 작동한다.

## 보안과 버퍼 오버플로 공격

가상 메모리 시스템에 있어 보안 문제는 중요하다. 주요한 위험 중 하나는 **버퍼 오버플로(buffer overflow)** 공격이다.

버퍼 오버플로 공격은 사용자 프로그램과 커널 모두에 영향을 줄 수 있는데, 공격의 아이디어는 공격자가 목표 시스템의 주소 공간에 임의의 데이터를 주입하는 버그를 이용하는 것이다. 가령 개발자가 예상한 입력의 범위보다 길게 입력하여, 버퍼의 경계를 넘어 목표의 메모리를 덮어쓸 수 있다.

```c
int	some_function(char *input) {
	char dest_buffer[100];
	strcpy(dest_buffer, input);
}
```
<br />

일반적으로 오버플로 오류는 치명적이지 않지만(운영체제가 알아서 크래시를 시킨다), 공격자는 정교하게 오버플로를 만들어, 원하는 위치에 코드를 집어넣고 임의의 연산을 실행하거나 CPU 사이클을 남에게 빌려줄 수 있다. 만약 운영체제를 대상으로 공격이 성공한다면, 공격자는 **권한 상승(privilege)**을 얻을 수도 있다.

버퍼 오버플로에 대한 최초의 그리고 가장 단순한 방어는, 주소 공간의 특정 영역(가령 스택)에 탑재된 어떤 코드도 실행할 수 없게 만드는 것이다. AMD가 x86버전에 도입한 **NX 비트(No-eXcute)**가 그 예이다. 하지만 이에 대응할 수 있는 **return-oriented programming(ROP)**를 이용한 아주 영리한 공격도 가능하다. 이는 현재 실행 중인 함수의 복귀 주소가 악성 명령어를 향하게끔 스택을 덮어쓰는 방식을 취한다(**return-to-libe** 공격). Linux는 이에 대응하기 위해 **address space layout randomization(ASRL)**이라는 또 다른 방어책을 추가한다. 이는 가상 주소 공간 내의 고정된 위치에 코드, 스택 및 힙을 배치하는 대신, 운영체제는 무작위의 위치에 이들을 매치한다. ASLR은 유용한 방어 수단으로 판단되어 **Kernel address space layout randomization(KASLR)**라는 기능으로 커널에 통합되었다.

## 다른 보안 관련 문제들: Meltdown And Spectre

2018년, 시스템 보안 세계는 두 가지 공격(**Meltdown**, **Spectre**)에 의해 혼란에 빠졌다. 각 공격에서 악용하는 일반적인 취약점은, 최신 CPU가 성능을 향상시키기 위해 온갖 방법을 수행한다는 것이다. 문재의 핵심이 되는 기법으로, CPU가 향후 실행될 명령을 추측하고 미리 실행하는 **Speculative execution**이 있는데, CPU의 이러한 추측은 시스템의 여러 부분에 *실행 흔적*을 남기는 경향이 있기 떄문이다. 공격자는 이러한 흔적을 사용하여 메모리 내용 심지어 MMU에 의해 보호되는 메모리까지도 취약하게 만들 수 있다.

커널 보호를 강화하는 한 가지 방법으로, 각 사용자 프로세스에서 커널 주소 공간을 최대한 제거하고, 별도의 커널 페이지 테이블을 사용하여 커널 데이터를 보관하는 **커널 페이지 테이블 격리(kernel page table isolation, KPTI)**라는 기법이 있지만, 페이지 테이블 전환에 많은 비용이 들어가게 된다. 보안과 성능 및 편의를 챙기는 일은 아주 어렵다.

위의 취약점을 자세하게 알고자 한다면 [meltdownattack.com](https://meltdownattack.com)과 [spectreattack.com](https://spectreattack.com)을 참조할 것.

-------

복잡하고 긴 이야기였지만, 시스템의 전체적인 구조를 쭉 훑어볼 수 있어 재미있는 시간이였다. 동시에 시스템의 아주 깊고 넓은 세계를 얼핏 볼 수 있었고, 아주 복잡하고 어렵지만 흥미로운 아이디어가 가득하다는 인상을 받았다. 아직 내 실력으로는 접근하기 엄두가 안나지만... 한 번 쯤은 그 세계에 발을 잠깐 담가보고 싶다는 생각도 든다.

이제 메모리 가상화 파트가 끝났다. 다음 파트는 운영체제의 병행성에 대해 다룬다.
