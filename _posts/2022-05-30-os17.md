---
title: "OSTEP - 가상화: 완전한 가상 메모리 시스템"
lang: "ko"
layout: post
date: 2022-05-30 00:01:13 +0900
categories: [os]
tags: [os]
---

이번 챕터에선 **VAX/VMS** 운영체제와 **Linux** 운영체제가 실제로 어떠한 방식으로 가상 메모리 시스템을 구현하였는지 살펴본다. (다만 꽤 전문적인 내용이여서 조금 어렵게 느껴진다...)  
이번 챕터와 관련은 없지만 문득 궁금했던 내용... 만약 프로그램 사이즈가 주소 공간보다 크다면?  
[https://stackoverflow.com/questions/15965718/what-happens-if-the-size-of-a-program-is-larger-than-virtual-memory](https://stackoverflow.com/questions/15965718/what-happens-if-the-size-of-a-program-is-larger-than-virtual-memory)  
아무튼... 이제 시작해보자.

# VAX/VMS 가상 메모리

VAX/VMS(또는 단순하게 VMS) 운영체제의 아키텍트는 "현대적인" 가상 메모리 관리자를 최초로 구현한 사례로 손꼽히며, 이에 사용된 다양한 기법과 접근법은 현재에도 꾸준히 사용중이라고 한다. VMS는 컴퓨터의 구조적 결함(하드웨어의 결함)을 소프트웨어로 보안한 훌륭한 사례이다.

## 메모리 관리 하드웨어

VAX-11은 프로세스마다 512바이트 페이지 단위로 나누어진 32비트 가상 주소 공간을 제공한다. 가상 주소는 23비트 VPN과 9비트 오프셋으로 구성되어 있다. VPN의 상위 2비트는 페이지가 속한 세그멘트를 나타내기 위해 사용되었으며, 따라서 해당 시스템은 페이징과 세그멘테이션의 하이브리드 구조를 갖고 있다고 말할 수 있다.

주소 공간의 *하위 절반*은 "프로세스 공간(P)"으로, 각 프로세스마다 다르게 할당된다. 해당 공간에는 사용자 프로그램과 힙 그리고 스택이 존재한다. 주소 공간의 *상위 절반*은 그 중 반만 사용되며, 이 공간을 "시스템 공간(S)"로 부른다. 해당 공간에는 운영체제의 보호된 코드와 데이터가 존재하며, 이로 인해 여러 프로세스가 운영체제를 공유할 수 있다.

512바이트 페이지는 아주 작은 크기이므로, 페이지 테이블의 크기가 엄청나게 커질 수 있고, 이는 메모리에 압박을 가할 수 있다. 이를 위해 VAX-11은 "프로세스 공간"을 두 개의 세그멘트로 나누어(P0, P1), 프로세스마다 각 영역을 위한 페이지 테이블을 가지게 함으로써, 페이지 테이블 공간이 스택과 힙 사이의 사용되지 않는 주소 영역을 할당하지 않도록 한다. 그리고 운영체제는 나누어진 페이지 테이블을 커널의 가상 메모리에 배치하여(즉 세그멘트 S에 공간을 할당하여), 페이지 테이블의 페이지들을 물리 메모리에서 디스크로 스왑할 수 있도록 하였다.

## 실제 주소 공간

```
0    +-----------------+ -+
     | page 0: invalid |  |
     +-----------------+  |
     |      code       |  |
     +-----------------+  +--> User (P0) 
     |      heap       |  |
     +-----------------+  |
     |                 |  |
2^30 +-----------------+ -+
     |                 |  |
     +-----------------+  +--> User (P1)
     |     stack       |  |
2^31 +-----------------+ -+
     |    trap table   |  |
     +-----------------+  |
     |   kernel data   |  |
     +-----------------+  |
     |   kernel code   |  +--> System (S)
     +-----------------+  |
     |   kernel heap   |  |
     +-----------------+  |
     |                 |  |
     +-----------------+ -+
     |      unused     |
2^32 +-----------------+

## VMX/VAX 주소 공간
```

위 그림을 보면, 페이지 0이 무효 처리 되어있어 접근이 불가능하다. 해당 페이지는 **널-포인터(null-pointer)** 접근을 검출하는 역할을 하며, 효과적인 디버깅을 지원한다. 또한 커널의 요소들이 사용자 주소 공간의 일부로 들어가있는데, 이로 인해 사용자 코드에서 문제가 발생하면(가령 문맥 교환), 운영체제는 주소 공간을 참조하기만 하면 되기에 처리하기 쉬워진다(커널이 자체 주소 공간을 가진다면 사용자 프로그램과 커널 간의 데이터 이동은 매우 복잡해진다). 동시에 운영체제의 자료를 보호하기 위해, 페이지 테이블의 protection bit에 보호 수준을 저장함으로써 페이지 별로 보호 수준을 다르게 설정한다. 즉 특정 페이지에 접근하기 위해선 특별한 권한이 요구된다.

## 페이지 교체

VAX의 페이지 테이블 항목(PTE)은 다음과 같은 비트를 가지고 있다:

1. 유효(valid) 비트
2. 보호 필드(protection field, 4비트)
3. 변경(modify, dirty) 비트
4. 운영체제가 사용하기 위해 예약한 비트(5비트)
5. 물리 프레임 번호(PFN)

여기에 **참조 비트(reference bit)**가 없는 것을 확인할 수 있다. VAX는 **세그멘트된 FIFO** 교체 정책을 수행함으로써 페이지 교체와 **메모리 호그(memory hog)**(메모리를 너무 많이 사용하는 프로그램)에 대처한다. 작동 원리는 간단하다. 먼저 각 프로세스는 **상주 집합 크기(resident set size, RSS)**(메모리에 유지할 수 있는 최대 페이지 개수)를 지정 받는다. 그리고 각 페이지들이 FIFO 리스트에 보관되며, 만약 페이지 개수가 RSS보다 커지면, *제일 먼저 들어온* 페이지가 쫓겨나는 방식이다.

FIFO의 성능을 개선하기 위해 시스템은 두 개의 **second-chance list**(*전역 클린-페이지 프리 리스트(global clean-page free list)*와 *더티-페이지 리스트(dirty-page list)*)를 도입하였다. 제거되는 페이지의 상태에 따라(수정되었는가? -> 더티, 수정되지 않았는가? -> 클린) 해당 페이지는 그에 맞는 리스트에 들어간다. 그리고 빈 페이지가 요구될 경우, 전역 클린 리스트에서 첫 번쨰 페이지를 꺼내어 디스크 접근을 최대한 피한다. 전역 second-chance list의 크기가 클 수록 세그멘트된 FIFO 알고리즘은 LRU와 유사하게 작동한다.

또한 VMS의 작은 페이지 크기를 극복하기 위해, 스왑의 I/O 효율을 개선하기 위한 최적화 기법으로 **클러스터링(clustering)**을 도입하였다. 클러스터링 기법을 사용하여 VMS는 전역 더티 리스트에 있는 페이지들을 묶어 한 번에 디스크로 보낸다.

## 그 외의 기법들

VMS는 이제는 표준화가 된 두 가지 기법을 더 가지고 있다: **요청시 0으로 채우기(demand zeroing)**와 **쓰기-시-복사(copy-on-write, COW)**.

일반적으로 힙에 페이지를 추가하는 요청이 들어오면, 운영체제는 물리 메모리에서 페이지를 찾아 0으로 채운 후, 주소 공간에 그 페이지를 매핑하는데(즉 페이지 테이블에 항목을 추가함), 만약 프로세스가 해당 페이지를 사용하지 않게 된다면, 많은 비용이 소모되어 버린다. **demand zeroing**은 반대로 해당 페이지를 먼저 페이지 테이블에 추가하고, 접근 불가능으로 설정한다. 만약 프로세스가 해당 페이지를 읽게 된다면, 운영체제로 트랩이 발생하여, 운영체제가 해당 페이지는 demand zeroing 페이지임을 알게 되고(일반적으로 '운영체제가 사용하기 위해 예약한 비트'에 정보가 표기되어 있다), 이후 페이지를 0으로 채우고 주소 공간에 해당 페이지를 매핑한다. demand zeroing에서는 먄약 프로세스가 해당 페이지를 접근하지 않는다면, 페이지를 주소 공간에 매핑하고 0으로 채우는 과정을 모두 생략할 수 있게 된다.

**copy-on-write**는, 운영체제가 주소 공간에서 다른 공간으로 페이지를 복사할 필요가 있을 떄, 복사를 하지 않고 해당 페이지를 대상 주소 공간으로 매핑한다(즉 하나의 물리 페이지를 두 개의 페이지 테이블이 가리키도록 한다). 만약 양쪽 주소 공간이 페이지를 읽기만 한다면, 운영체제는 데이터 이동 없이 빠른 복사를 구현하게 되는 셈이다(불필요한 복사를 피할 수 있게 된다). 만약 한 공간이 페이지 쓰기를 시도한다면, 트랩이 발생하고 운영체제는 해당 페이지가 COW 페이지임을 파악한 후, 새로운 페이지를 할당하여 해당 주소 공간에 매핑한다.

demand-zeroing, copy-on-write는 모두 *게으르게* 일을 처리함으로써, 불필요한 과정을 최소화하여 성능을 개선한다는 공통점이 있다고 말할 수 있을 것 같다.

# Linux 가상 메모리 시스템

작성 중...
