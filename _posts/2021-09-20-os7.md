---
title: "OSTEP - 가상화: 멀티프로세스 스케줄링"
lang: "ko"
layout: post
date: 2021-09-20 02:25:01 +090링
categories: [os,]
tags: [os,]
---

역시 최대한 간결한 정리를 노력하고 있다...

현대 컴퓨터는 여러 개의 CPU가 하나의 칩에 내장된 멀티코어(multicore) 프로세서를 사용한다. 동시에 CPU가 프로그램을 처리하는 방법도 복잡하게 바뀌게 된다. 기존의 전통적 응용프로그램은 오직 하나의 CPU만 사용하였기에, 단순히 CPU를 추가한다고 해서 속도 향상이 발생하지 않는다. 이 문제를 해결하기 위해선, 프로그램을 **병렬(parallel)**로 실행되도록 작성하거나(가령, **쓰레드**를 사용하여, 하지만 이는 이후에 다룰 내용이다) 작업을 여러 CPU에 스케줄 할 수 있도록 운영체제의 스케줄링 방법을 변경해야 했다. 이를 위한 운영체제의 스케줄링 방법을 **멀티프로세서 스케줄링(multiprocessor scheduling)**이라고 말한다. 멀티프로세서 구조에 대한 전반적인 이해를 하기 위해 간단히 CPU 하드웨어에 관한 내용을 먼저 짚고 넘어가자.

# 멀티프로세서에 대한 전반적인 이해

```
+--------------------+
|                    |          
|                    |          
|                    |          
|                    |          
|         CPU        |          
|                    |          
|                    |          
|                    |          
|                    |          
|                    |          
+--------------------+          
|                    |          
|        Cache       |          
|                    |          
+----------|---------+          
           |                    
           |                    
           |                    
           |                    
+--------------------+          
|                    |          
|       Memory       |          
|                    |          
+--------------------+   
```

**캐시**는 메인 메모리에서 _자주_ 사용되는 데이터의 복사본을 저장하는 작고 빠른 메모리이다. 메인 메모리가 모든 데이터를 저장하고 있지만, 이를 CPU로 가져오는 시간은 느리다. 속도 개선을 위해, 자주 접근되는 데이터를 캐시에 임시로 저장함으로써, 사실은 캐시에서 CPU로 데이터를 가져오는 것이지만, 마치 메인 메모리에서 CPU로 데이터를 가져오는 과정이 매우 빠르게 보이는 듯한 환상을 사용자에게 제공한다.

프로세서는 이후에 다시 사용될 것이라고 예상한 데이터의 복사본을 CPU 캐시에 저장한다. 프로세서는 데이터의 **시간 지역성(temporal locality)**과 **공간 지역성(spatial locality)**에 기반하여 캐시에 저장한다. 시간 지역성은 한 번 접근된 데이터는 가까운 미래에 다시 접근되기 쉬움을 의미한다. 가령, 루프에서 접근되는 변수가 그렇다. 공간 지역성은, 접근된 데이터 주변의 데이터가 접근되기 쉬움을 의미한다. 가령, 배열에 접근하는 프로그램이 그렇다.

```
+--------------------+        +--------------------+
|                    |        |                    |
|                    |        |                    |
|                    |        |                    |
|                    |        |                    |
|         CPU        |        |         CPU        |
|                    |        |                    |
|                    |        |                    |
|                    |        |                    |
|                    |        |                    |
|                    |        |                    |
+--------------------+        +--------------------+
|                    |        |                    |
|        Cache       |        |        Cache       |
|                    |        |                    |
+----------|---------+        +----------|---------+
           |                             |          
           |                             |          
           |                             |          
           |                             |          
           ---------------|---------------          
                          |                         
               +----------|---------+               
               |                    |               
               |       Memory       |               
               |                    |               
               +--------------------+   
```

하지만 하나의 시스템에 여러 프로세서가 존재하고, 하나의 공유 메인 메모리가 있는 멀티프로세서 시스템의 경우, 캐시 사용은 복잡해진다. 하나의 프로그램을 두 개의 프로세서가 접근할 때, 하나의 프로세서의 캐시 내에서 프로그램의 변수의 값이 변하는 과정을 다른 프로세서가 파악하지 못하여(왜냐하면 캐시는 메인 메모리와 다르게 각 프로세서에 독립적으로 할당되어 있기 떄문이다), 같은 변수를 두고 서로 다른 값(변하기 전의 값과 변화 이후의 값)으로 프로그램을 실행함으로써 오류가 발생하는 문제가 생길 수 있는데, 이를 **캐시 일관성 문제(cache coherence)**라고 한다. 이를 위한 기본적인 해결책은 하드웨어에 의해 제공된다. 하드웨어가 메모리 값의 갱신을 항상 주시함으로써 각 프로세서에 모두 공유될 수 있도록 하는 것이다.

하드웨어 문제 외에도, 프로그램 또는 운영체제에 남겨진 문제들이 있다. 가령, CPU들이 동일한 데이터 또는 구조체에 접근할 때, 올바른 연산 결과를 보장하기 위해 **락-프리(lock-free)**와 같은 상호 배제를 보장하는 동기화 방법이 사용된다. 또한 하나의 프로그램이 실행된 CPU위에서 해당 프로그램이 실행되어야 캐시에 저장된 데이터를 사용할 수 있고, 반대로 다른 프로그램이 들어오게 된다면, 새로운 데이터를 다시 캐시에 탑재하게 되는 비효율이 발생하기에, 가능한 한 프로세스를 동일한 CPU에서 실행하도록 만드는 **캐시 친화성(cache affinity)**의 구현이 필요하다.

# 멀티프로세서 시스템 스케줄링 방법

1. 단일 큐 멀티프로세서 스케줄링(single queue multiprocessor scheduling, SQMS)
**SQMS**는 단일 프로세서 스케줄링의 기본 프레임워크를 그대로 사용하는 방법이다. 가령, CPU는 하나의 작업을 선택하고자 한다. 이 방식은 단순하지만, **확장성(scalability)**이 결여되어 있다(락에 대한 경젱의 증가로 시스템에 과부하가 걸린다는 이야기인데, 아직 병행성 파트를 읽지 않아서 자세히 모르겠다...). 그리고 캐시 친화성 문제를 가지고 있다. 작업 스케줄과 프로세서가 다음과 같은 경우:

```
Queue: A -> B -> C -> D -> E -> NULL

CPU0: A E D C B ...
CPU!: B A E D C ...
CPU2: C B A E D ...
CPU3: D C B A E ...
```

각 CPU는 공유 큐에서 다음의 작업을 선택함으로써, 캐시 친화성을 만족하지 못한다. 이 문제의 해결을 위해 대부분의 SQMS 스케줄러는 가능한 한 프로세스가 동일한 CPU에서 재실행될 수 있도록 제어한다.

```
CPU0: A E A A A ...
CPU1: B B E B B ...
CPU2: C C C E C ...
CPU3: D D D D E ...
```

캐시 친화적인 프로그램을 제외한 프로그램은(여기서는 E) 프로세서의 오버헤드를 균등하게 하기 위해 다른 프로세서로 이동한다. 하지만 이러한 기법의 구현은 복잡해질 수 있다고 한다.

2. 멀티 큐 멀티프로세서 스케줄링(multi-queue multiprocessor scheduling, MQMS)
**MQMS**는 SQMS와 다르게, CPU마다 큐를 하나씩 가지고 있다. 각 큐는 특정 스케줄링 규칙을 따르고 있고, 작업이 시스템에 들어가면 특정한 방법에 의해 하나의 스케줄링 큐에 배치된다. 이로 인해 작업이 독립적으로 스케줄되어, 이전의 단일 큐에서 발생하였던 정보의 공유 및 동기화 문제를 피할 수 있게 된다.

```
Q0 -> A -> C
Q1 -> B -> D

/* using Round-Robin */
CPU0: A A C C A A C C ...
CPU1: B B D D B B D D ...
```

MQMS의 이점은, CPU의 개수가 증가함으로써 큐의 개수도 증가하여, 락과 캐시 경합(cache contention)이 문제가 되지 않고(즉, 확장성이 좋고), 작업이 같은 CPU에서 진행되기 때문에, 본질적으로 캐시 친화적이라는 것이다. 하지만 MQMS는 **워크로드의 불균형(load imbalance)**이라는 근본적인 문제를 가지고 있다. 만약 위의 경우에서, 작업 C가 끝났다면, A가 B와 D보다 CPU를 두 배 차지하게 될 것이며(A A A A A ...), 만약 A도 끝나게 된다면, CPU0은 이후 아무런 작업도 하지 않게 됨을 생각해볼 수 있다. 이를 해결하기 위해선, 하나의 프로세서의 작업을 다른 프로세서로 이동시키는 **이주(migration)** 기술을 사용한다. 가령, 몇 번의 타임슬라이스 후, 한 프로세서의 작업을 다른 프로세서로 지속적으로 옮기는 방법은 다음과 같다:

```
Q0 -> A
Q1 -> B -> D

CPU0: A A A A B A B A B B B B ...
CPU1: B D B D D D D D A D A D ...
```

당연히 위와 같은 패턴만 존재하는 것은 아니다. 중요한 점은, 어떤 작업을 이주해야 하는 것인가에 관한 것인데, 이를 위한 한 가지 접근 방식으로, **작업 훔치기(work stealing)**이라는 방법이 있다. 작업 훔치기에서는 작업의 개수가 낮은 큐가 가끔 다른 큐에 훨씬 많은 수의 작업이 있는지 검사한 뒤, 작업이 많은 큐의 작업의 일부를 작업이 적은 큐로 이주시킨다. 이러한 방식은 자연스러운 문제가 있다. 큐를 너무 자주 검사한다면 높은 오버헤드로 인해 확장성에 문제가 생긴다. 반면 큐를 자주 검사하지 않는다면, 워크로드 불균형 문제는 해결되지 않는다.

# Linux 멀티프로세서 스케줄러
Linux에는 O(1) 스케줄러, CFS 스케줄러, BFS 스케줄러가 있다고 한다. O(1)과 CFS는 멀티 큐를, BFS는 단일 큐를 사용하고, O(1)은 MLFQ와 유사하게 우선순위를 기반으로 하는 스케줄러이고, CFS는 보폭 스케줄러처럼 결정론적(deterministic) 비례배분(proportional share) 방식이며, BFS는 비례배분 방식과 더해 Earliest Eligible Virtual Deadline First(EEVDF)라는 복잡한 알고리즘에 기반한다고 한다.

# 정리
SQMS는 구현이 용이하고 워크로드의 균형을 맞추기 쉽지만, 많은 개수의 프로세서에 대한 확장성과 캐시 친화성이 좋지 않다. MQMS는 확장성이 좋고 캐시 친화적이지만, 워크로드 불균형 문제를 가지고 있고 구현이 복잡하다. 

이로써 CPU 가상화에 대한 파트는 모두 끝이 났다.