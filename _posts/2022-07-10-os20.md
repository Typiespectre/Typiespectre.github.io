---
title: "OSTEP - 병행성: 락"
lang: "ko"
layout: post
date: 2022-07-10 18:21:30 +0900
categories: [os]
tags: [os]
---

프로그래머들은 소스 코드의 임계 영역을 락으로 둘러서, 그 임계 영역이 마치 하나의 원자 단위 명령어인 것처럼 실행되도록 한다. 락으로 코드를 보호하지 않으면, 프로세서의 인터럽트 혹은 멀티 쓰레드의 병행성으로 인해 데이터 경쟁이 발생하게 된다.

**(주의)** : 여기에 나오는 코드는 대부분 의사 코드이다!

## 락: 기본 개념

```c
lock_t	mutex;	// 글로벌 변수로 선언된 락
...
lock(&mutex);
balance = balance + 1;	// 공유 변수의 갱신
unlock(&mutex);
```
<br />

쓰레드 간 **상호 배제(mutual exclusion)** 기능을 제공하기 때문에 POSIX 라이브러리는 락을 **mutex**라고 부른다. 락은 일종의 변수다. 락을 사용하기 위해서는 락 변수를(위에 사용한 `mutex`와 같이) 먼저 선언해야 한다. **락 변수**는 락의 상태를 나타내는데, 락의 상태로 하나는 **사용 가능** 상태(어떤 쓰레드도 락을 소유하지 않은 상태), 다른 하나는 **사용 중** 상태(임계 영역에서 정확히 하나의 쓰레드가 락을 획득한 상태)가 있다. 락 자료 구조에는 락을 보유한 쓰레드에 대한 정보나 락을 대기하는 쓰레드들에 대한 정보를 저장할 수도 있다.

`lock()` 루틴을 호출할 떄, 만약 어떤 쓰레드도 락을 갖고 있지 않으면 해당 쓰레드는 락을 획득하고 임계 영역 내로 진입한다. 해당 쓰레드는 락 **소유자(owner)**로 불린다. 락 소유자가 존재하는 상태에서는 다른 쓰레드들이 임계 영역으로 진입할 수 없다. 락 소유자가 `unlock()`을 호출하면 대기중이던 쓰레드가 락을 획득하여 임계 영역으로 진입하게 된다. 락을 통해 프로그래머는 프로세스들의 혼란스러운 실행 순서에 어느 정도의 질서를 부여할 수 있다.

## Pthread 락

위의 락 코드를 POSIX 쓰레드 코드로 변환해보자.

```c
pthread_mutex_t	lock = PTHREAD_MUTEX_INITIALIZER;
...
Pthread_mutex_lock(&lock);
balance = balance + 1;
Pthread_mutex_unlock(&lock);
```
<br />

POSIX에서는 락과 언락 함수에 락의 변수명을 인자로 전달한다. 이러한 방식을 통해 많은 일을 처리할 수 있는데, 하나의 락으로 모든 임계 영역들을 보호하는 것(**coarse-grained**)이 아니라, 다수의 쓰레드가 서로 다른 락으로 보호된 코드를 실행(**fine_grained**)하게 할 수도 있다.

그렇다면 효율적인 락을 만들기 위해 어떤 일을 해야하고, 어떠한 지원이 필요할까? 실제로 사용 가능한 락을 만들기 위해선 하드웨어와 운영체제의 도움을 받아야 한다.

## 락의 평가

락의 정상동작 여부 판단을 위한 평가기준은 세 가지가 있다:

* **상호 배제**
* **공정성(fairness)** (쓰레드들의 락 획득에 대한 공정한 기회가 주어지는가? 또는 락을 전혀 얻지 못해 **굶주리는(starve)** 쓰레드가 발생하지는 않는가?)
* **성능(performance)** (쓰레드 간 경쟁이 전혀 없는 경우, 여러 쓰레드가 단일한 CPU에서 락을 획득하려고 경쟁하는 경우, 멀티 CPU에서의 경쟁 상황)

## 인터럽트 제어

초창기 단일 프로세스 시스템에서는 상호 배제 지원을 위해 임계 영역 내에서는 인터럽트를 비활성화하는 방법을 사용했었다.

```c
void	lock() {
	DisableInterrupts();
}
void	unlock() {
	EnableInterrupts();
}
```
<br />

이 방법의 주요 장점은 단순하다는 것이다. 임계 영역 내의 코드에서는 인터럽트가 발생할 수 없다. 인터럽트가 발생하지 않으면, 코드가 실행 중일 때 다른 쓰레드가 중간에 끼어들지 않는다는 것을 보장할 수 있다.

하지만 이 방법에는 단점도 많은데, 먼저 이 요청을 하는 쓰레드에 **특권(privileged)** 연산을 실행할 수 있도록 허가해야 한다는 것이다(운영체제가 잘 알지 못하는 다른 프로그램을 신뢰해야 하는 경우가 생긴다면, 대부분 곤경에 빠진 것이라고 보면 된다). 또한 탐욕적인 프로세스가 lock을 호출하면, 프로세서를 독점하여 사용하게 된다. 더 나아가 악의적인 프로그램이 lock을 호출하고 무한 반복문에 들어가면, 운영체제는 시스템의 제어권을 다시 얻을 수 없다. 무엇보다 위의 방법은 멀티프로세서에는 적용할 수 없다. 특정 프로세서에서 인터럽트가 발생하더라도, 다른 프로세서는 여전히 동작할 수 있다. 그리고 장시간 인터럽트를 중지시키는 것은 중요한 인터럽트의 시점을 놓칠 수 있다. 또한 이 방법은 느리게 실행되는 경향이 있어 비효율적이다.

이러한 이유로 인터럽트를 비활성화하는 것은 제한된 범위에서만 사용되어야 한다.

## 실패한 시도: 오직 load/store 명령어만 사용하기

인터럽트 활성/비활성 방법을 사용하지 않고 락을 구현하려면 CPU 하드웨어와 락 구현을 위한 명령어를 사용해야만 한다. 단일 플래그 변수를 사용하여 락을 구현할 수 있을까? 불가능하다는 결론이 나온다.

```c
typedef struct	__lock_t { int flag; } lock_t;

void	init(lock_t *mutex) {
	// 0 -> 락이 사용 가능함, ` -> 락 사용 중
	mutex->flag = 0;
}

void	lock(lock_t *mutex) {
	while (mutex->flag == 1)	// flag 변수를 검사(test)함
	;	// spin-wait (do nothing)
	mutex->flag = 1;		// 이제 설정(set)한다!
}

void	unlock(lock_t *mutex) {
	mutex->flag = 0;
}
```
<br />

임계 영역에 진입하는 첫 쓰레드가 lock()을 호출하면, 플래그 값이 1인지 **검사(test)**하고(첫 번째 경우는 1이 아니다), 플래그의 값을 1로 **설정(set)**하여 이 쓰레드가 락을 **보유(hold)**하고 있다고 표시한다. 임계 영역에서 나오면 쓰레드가 unlock()을 호출하여 플래그 값을 초기화한다.

만약 첫 번쨰 쓰레드가 임계 영역 내에 있을 때 다른 쓰레드가 lock()을 호출하면, 그 쓰레드는 `while` 문으로 **spin-wait**을 하며 처음 쓰레드가 unlock()을 호출하여 플래그를 초기화하기를 기다린다. 처음 쓰레드가 플래그를 초기화하면 대기하던 쓰레드는 `while` 문에서 빠져나와 플래그를 1ㄹ로 설정하고 임계 영역 내로 진입한다.

이 코드에는 두 가지 문제가 있다. 먼저, 두 쓰레드 모두 플래그를 1로 설정하는 경우가 생겨 임계 영역에 두 쓰레드 다 진입할 수 있게 된다. 따라서 상호 배제 제공이라는 기본 요구 조건을 보장하는데 실패한다.

```
Thread 1                    Thread 2
----------------------------------------------------
call lock ()
while (flag == 1)
Interrupt
                            call lock()
                            while (flag == 1)
                            flag = 1;
                            Interrupt;
flag = 1;
```
<br />

또한 **spin-wait**는 다른 쓰레드가 락을 해제할 때까지 시간을 낭비하는데, 이 방법은 단일 프로세서에 매우 큰 손해를 준다. 락을 소유한 쓰레드조차 실행할 수 없게 되기 때문이다.

## Test-And-Set을 사용하여 작동하는 스핀 락 구현하기

단일 플래그 변수만으로는 제대로 된 락을 구현할 수 없기에, 하드웨어가 락을 지원할 필요성이 생기게 되었다. 하드웨어 기법 중 가장 기본은 **test-and-set** 명령어 또는 **원자적 교체(atomic exchange)**로 알려진 명령어이다.

```c
int	TestAndSet(int *old_ptr, int new) {
	int old = *old_ptr;	// old_ptr의 이전 값을 가져옴
	*old_ptr = new;		// old_ptr에 'new'의 값을 저장함
	return old;		// old의 값을 반환함
}
```
<br />

`TestAndSet`은 `ptr`이 가리키고 있던 예전의 값을 반환하면서 동시에 `new`라는 새로운 값을 저장한다. 핵심은 이러한 동작들이 원자적으로 수행된다는 점이다. `TestAndSet`으로 아래와 같은 간단한 스핀 락을 만들 수 있다.

```c
typedef struct	__lock_t {
	int	flag;
} lock_t;

void	init(lock_t *lock) {
	// 0은 락이 획득 가능한 상태를 표시, 1은 락을 획득했음을 표시
	lock->flag = 0;
}

void	lock(lock_t *lock) {
	while (TestAndSet(&lock->flag, 1) == 1)
	;	// 아무 일도 하지 않음, 스핌
}

void	unlock(lock_t *lock) {
	lock->flag = 0;
}
```
<br />

flag가 0인 첫 번째 쓰레드가 `TestAndSet`을 호출하면, 해당 루틴은 0을 반환하고 flag 값을 1로 설정하여 락을 보유하고 있음을 표시한다, 이전의 flag 값(0)을 검사한 쓰레드는 `while` 문에서 회전하지 않고 락을 획득할 수 있다.

처음 쓰레드가 락을 획득하여 flag값이 1이 된 상황에서, 두 번째 쓰레드가 lock()을 호출하는 경우, `TestAndSet` 루틴은 예전 값으로 1을 반환하는 동시에, flag 값을 다시 1로 설정한다. 락을 보유하고 있는 쓰레드가 있는 한, `TestAndSet`은 계속 1을 반환한다. 두 번째 쓰레드는 락이 해제될 떄까지 계속 `while`문을 반복하게 된다.

락의 값을 **검사(test)**하고 새로운 값으로 **설정(set)**하는 동작을 원자적으로 만듦으로써 오직 하나의 쓰레드만 락을 획득할 수 있도록 만들었다. 단일 프로세서에서 이러한 **스핀 락**의 방식을 제대로 사용하기 위해선 **선점형 스케줄러(preemptive scheduler)**를 사용해야 한다.

## 스핀 락 평가

* 상호 배제: 스핀 락은 임의의 시간에 단 하나의 쓰레드만이 임계 영역에 제대로 진입할 수 있다. 통과.
* 공정성: 스핀 락은 어떠한 공정성도 보장해줄 수 없다. `while`문을 회전 중인 쓰레드는 경쟁에 밀려 굶주릴 수 있다. 탈락!
* 성능: 단일 CPU의 경우, CPU 사이클이 낭비된다. 멀티 프로세서의 경우, 락을 획득하기 위해 쓰레드가 기다리는 동안 다른 프로세서는 다른 일을 할 수 있기에, CPU 사이클을 크게 낭비하지 않는다. 중립.

## Compare-And-Swap

```
int	CompareAndSwap(int *ptr, int expected, int new) {
	int	original = *ptr;
	if (original == expected)
		*ptr = new;
	return original;
}
```
<br />

`Compare-And-Swap` 기법은 `ptr`이 가리키고 있는 주소의 값이 `expected` 변수와 일치하는지 검사 후, 일치한다면 `ptr`이 가리키는 주소의 값을 새로운 값으로 변경하고, 그렇지 않다면 아무것도 하지 않는다. 그리고 원래의 메모리 값을 반환하여 함수를 호출한 코드의 락 획득 성공 여부를 알 수 있도록 한다. `Compare-And-Swap` 방법은 앞선 `Test-And-Set`과 유사하게 동작한다. (`TestAndSet`과 다르게 **대기없는 동기화(wait-free synchronization)**가 가능하다는 점에서 더 강력하다고 하는데, 이는 이후에 다루게 될 것 같다.)

## Loaded-Linked 그리고 Stored-Conditional

MIPS는 임계 영역 진입 제어 함수를 제작하기 위한 명령어 쌍(**load-linked**, **store-conditional**)을 제공한다. `load-linked`는 일반 로드 명령어와 같이 메모리 값을 레지스터에 저장한다. `store-conditional` 명령어는 동일한 주소에 다른 스토어가 없었던 경우에만 저장하고, 저장이 성공하면 `load-linked`가 탑재했던 값을 갱신하고 1을 반환한다. 실패할 경우, 값을 갱신하지 않고 0을 반환한다.

```c
void	lock(lock_t *lock) {
	while (1) {
		while (LoadLinked(&lock->flag) == 1)
		;
	if (StoreConditional(&lock->flag, 1) == 1)
		return;	// 1로 변경하는 것이 성공하였다면 완료, 아니라면 처음부터 다시 시도
	}
}

void	unlock(lock_t *lock) {
	lock->flag = 0;
}
```
<br />

락이 획득 가능한 상태가 되면(flag가 0인 경우), 쓰레드는 `store-conditional` 명령어로 락 획득을 시도하고, 만약 성공한다면 쓰레드는 flag값을 1로 변경한다. 그리고 임계 영역 내로 진입한다.

`store-conditional` 명령어가 실패할 경우, 쓰레드는 `lock()`을 다시 호출하여 `load-linked`를 실행하고, 락이 사용 가능한 상태이므로 0을 반환한다. 만약 두 쓰레드가 flag를 0으로 갖고, 동시에 락을 호출한다고 해보자(즉, 두 쓰레드 모두 `load-linked` 명령어를 실행하였고 각자가 `store-conditional`을 부르려는 상황이다). `store-conditional` 명령어의 주요 기능은, 오직 하나의 쓰레드만 flag 값을 1로 설정하여 락을 획득할 수 있도록 한다.

## Fetch-And-Add

`Fetch-And-Add` 명령어는 원자적으로 특정 주소의 예전 값을 반환하면서 값을 증가시킨다.

```c
int	FetchAndAdd(int *ptr) {
	int	old = *ptr;
	*ptr = old + 1;
	return old;
}
```
<br />

하나의 변수만을 사용하는 대신 이 해법에서는 티켓(ticket)과 차례(turn) 조합을 사용하여 락을 만든다(**티켓 락**). 하나의 쓰레드가 락 획득을 원하면 티켓을 부여하고 리턴한다. 다음 쓰레드의 차례를 결정하기 위해 티켓이 부여되면 다음 티켓은 값이 1이 증가된다. 루틴은 현재 쓰레드의 티켓과 차례 값을 비교하여, 차례가 된 쓰레드에게 락을 제공한다. 언락 동작은 차례 변수의 값을 증가시켜 대기 중인 다음 쓰레드에게 임계 영역 진입 차례를 넘겨준다.

이전까지의 접근 방법과 이번 해법의 중요한 차이 중 하나는 모든 쓰레드들이 각자의 순서에 따라 진행된다는 것이다. 쓰레드가 티켓 값을 할당받았다면 미래의 어느 떄에 실행되기 위해 스케줄되어 있다는 것이다. 이전까지의 해법들에서는 이러한 보장이 없었다. 어떤 쓰레드들은 락을 획득하고 해제할 수 있지만, 어떤 쓰레드는 계속 회전만 하는 경우가 발생할 수 있다.

```c
typedef struct __lock_t {
	int	ticket;
	int	turn;
} lock_t;

void	lock_init(lock_t *lock) {
	lock->ticket = 0;
	lock->turn = 0;
}

void	lock(lock_t *lock) {
	int	myturn = FetchAndAdd(&lock->ticket);
	while (lock->turn != myturn)
	;
}

void	unlock(lock_t *lock) {
	FetchAndAdd(&lock->turn);
}
```
<br />

## 요약: 과도한 스핀

위의 하드웨어 기반의 락은 간단하고 제대로 동작한다. 하지만 이런 경우를 생각해보자: 두 개의 쓰레드와 하나의 프로세서가 있다. 쓰레드 0이 임계 영역 내에 있어서 락을 보유한 상태로 인터럽트에 걸렸다. 쓰레드 1은 락을 대기하며 타이머 인터럽트가 발생하기 전까지 스핀한다. N개의 쓰레드가 하나의 락을 획득하기 위해 경쟁하게 되면 상황은 더욱 심각해진다. 문맥 교환이 되어 쓰레드가 실행이 되었지만 이전 쓰레드가 인터럽트에 걸리기 전에 락을 이미 획득한 상태라면 그 쓰레드가 락을 해제하기를 기다리며 다른 쓰레드들은 스핀만 무한히 하게 된다. 그렇다면 어떻게 스핀에 CPU 시간을 낭비하지 않는 락을 만들 수 있을까?

## 간단한 접근법: 조건 없는 양보!

이 방법은 락이 해제되기를 기다리며 스핀하게 되는 경우, 자신에게 할당된 CPU를 다른 쓰레드에게 양보하는 것이다. 만약 한 쓰레드가 lock()을 호출하였지만 다른 쓰레드가 락을 보유한 상황이라면, 한 쓰레드가 갖고 있던 CPU 시간을 양보하여 다른 쓰레드가 임계 영역 밖으로 나올 수 있도록 돕는다. 100개의 쓰레드들이 락을 획득하기 위해 경쟁하고 있다면, 99개의 쓰레드가 락을 갖고 있는 하나의 쓰레드를 위해 CPU를 양보한다. 이전의 스핀 방식보다는 좀 더 좋긴 하지만 여전히 문맥 교환 비용이 상당하며 낭비가 많다. 무엇보다 어떤 쓰레드는 무한히 양보만 하는 경우가 발생할 수 있기에, 굶주림 문제는 여전히 해결되지 않는다.

## 큐의 사용: 스핀 대신 잠자기

굶주림 문제는 다음 실행될 쓰레드의 선택이 운에 맡겨지기에 발생한다. 스케줄러는 다수의 쓰레드가 락을 대기하고 있을 경우, 다음으로 락을 획득할 쓰레드를 명시적으로 선택할 수 있도록 해야 한다. 이를 위해서는 운영체제의 적절한 지원과 큐를 이용한 대기 쓰레드들의 관리가 필요하다.

Solaris는 `park()`와 `unpark(threadID)`라는 두 개의 호출문이 있다. `park()`는 호출하는 쓰레드를 잠재우는 함수이고 `unpark(threadID)`는 특정 쓰레드를 깨우는 함수이다. 이러한 루틴과 큐를 사용하여 이전의 `Test-And-Set`을 기아 현상에서 피할 수 있도록 만들어보자:

```c
typedef struct	__lock_t {
	int	flag;
	int	guard;
	queue_t	*q;
} lock_t;

void	lock_init(lock_t *m) {
	m->flag = 0;
	m->guard = 0;
	queue_init(m->q);
}

void	lock(lock_t *m) {
	while (TestAndSet(&m->guard, 1) == 1)
	;	// 회전하면서 guard 락을 획득
	if (m->flag == 0) {
		m->flag = 1;	// 락을 획득함
		m->guard = 0;
	} else {
		queue_add(m->q, getid());
		m->guard = 0;
		park();
	}
}

void	unlock(lock_t *m) {
	while (TestAndSet(&m->guard, 1) == 1)
	;	// 회전하면서 guard 락을 획득
	if (queue_empty(m->q))
		m->flag = 0;	// 락을 포기함: 누구도 락을 원하지 않음
	else
		unpark(queue_remove(m->q));	// 락을 획득함(다음 쓰레드를 위해)
	m->guard = 0;
}
```
<br />

`guard` 변수는 큐와 `flag` 변수를 보호한다. `lock()`에서 쓰레드가 락을 획득할 수 없을 때, `getid()` 함수를 호출하여 자신의 쓰레드 ID를 큐에 추가하고, `guard`를 0으로 설정하고 CPU를 양보한다.

만약 쓰레드가 `park()`를 호출하기 직전 락을 소유한 쓰레드가 락을 해제하는 경우, 락을 소유한 쓰레드는 락을 해제하며 꺠울 쓰레드의 존재 여부를 검사하는데, 대기 중인 쓰레드가 없는 상황이므로 락을 소유한 쓰레드는 락을 해제하고 실행을 계속하게 되어, `park()`를 호출한 쓰레드는 블럭상태가 되어버린다. 이러한 경쟁조건을 **wakeup/waiting race**라고 부른다.

Solaris는 `setpark()`를 호출하여 이 문제를 해결하였다. 이 루틴은 쓰레드가 현재 `park()`를 호출하기 직전이라는 것을 표시하는데, 만약 인터럽트가 실행되어 `park()`가 호출되기 전에 다른 쓰레드가 `unpark()`를 먼저 호출한다면, 추후 `park()` 호출 시, 이를 호출한 쓰레드는 블럭되기 전에 바로 리턴된다.

```c
queue_add(m->q, getid());
setpark();
m->guard = 0;
```
<br />

## 다른 운영체제, 다른 지원, 2단계 락

Linux는 **futex**라는 것을 지원하는데, 이는 Solaris의 인터페이스와 유사하지만 커널 내부와 좀 더 밀착되어 있다. 또한 Linux의 락은 **2단계 락(two-phase lock)**이라 불리는 특성을 가지는데, 첫 번째 회전하는 단계에서는 그대로 대기하지만, 첫 번째 단계에서 락을 획득하지 못한다면, 두 번째 단계로 진입하여, 락 해제 시 블럭된 쓰레드 중 하나를 잠에서 깨운다. (리눅스의 락에 대해선 아직 정확하게 이해하지 못하였다...)

## 요약

락은 일부 하드웨어 지원(강력한 명령어의 형태)과 일부 운영체제의 지원(`park()`와 같은 형태)으로 구현된다. 락은 하드웨어 환경에 적합하게 각기 다르게 최적화되어 있다.
